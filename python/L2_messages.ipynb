{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "190a3c14-4a67-4d64-9378-0b9737e4a5f7",
   "metadata": {},
   "source": [
    "# âœ‰ï¸ Messages\n",
    "  <img src=\"./assets/LC_Messages.png\" width=\"500\">\n",
    "\n",
    "Messages are the fundamental unit of context for models in LangChain. They represent the input and output of models, carrying both the content and metadata needed to represent the state of a conversation when interacting with an LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c566d2-7844-4901-af65-4a6e58817716",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf6ad0d-4efd-4066-9a8d-ca8bb0de94ef",
   "metadata": {},
   "source": [
    "Load and/or check for needed environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa9fb12-98e3-490d-9ae6-885054c8f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from env_utils import doublecheck_env\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Check and print results\n",
    "doublecheck_env(\".env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579f27b5-a53a-4f24-9480-6af61823d4e6",
   "metadata": {},
   "source": [
    "## HumanğŸ‘¨â€ğŸ’» and AI ğŸ¤– Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ca38b8-7514-4e18-b141-86f77c684ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"groq:llama-3.1-8b-instant\", \n",
    "    system_prompt=\"You are a helpful banker. Answer customer queries with warmth and professionalism.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e517775-cdac-43ab-a40b-1a9e8deaa666",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_msg = HumanMessage(\"Hello, I am looking for a home loan. What are your current interest rates?\")\n",
    "\n",
    "result = agent.invoke({\"messages\": [human_msg]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bcefc1-53d7-4723-a3dc-d87983be761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c37ca3-70f7-4f76-8108-94210ba7f5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(result[\"messages\"][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e186f7e-8818-4de4-bebd-4f73cebe5dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in result[\"messages\"]:\n",
    "    print(f\"{msg.type}: {msg.content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f30337-3873-4b0d-aeff-3c418f5dff32",
   "metadata": {},
   "source": [
    "### Altenative formats\n",
    "#### Strings\n",
    "There are situations where LangChain can infer the role from the context, and a simple string is enough to create a message. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2450c1b-924a-422c-bac3-62b1f03dc25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''agent = create_agent(\n",
    "    model=\"groq:llama-3.1-8b-instant\",\n",
    "    system_prompt=\"You are a terse sports poet.\",  # This is a SystemMessage under the hood\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9a9f83-79d4-4abe-b1e3-45ef58d2f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke({\"messages\": \"Does the bank offer any special home loan program or reduced rates for salaried employees?\"})   # This is a HumanMessage under the hood\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1544d7-3590-42e9-a56b-0dfb34f28505",
   "metadata": {},
   "source": [
    "#### Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b11e46-9c25-4828-9c6a-29a4594acdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke(\n",
    "    {\"messages\": {\"role\": \"user\", \"content\": \"How long does it take to clear a cheque?\"}}   # This is a HumanMessage under the hood\n",
    ")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00905cbe-b248-496f-898c-d223cd1fd0d7",
   "metadata": {},
   "source": [
    "There are multiple roles:\n",
    "```python\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a sports poetry expert who completes haikus that have been started\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a haiku about sprinters\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Feet don't fail me...\"}\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b31b4c-00f0-4b37-8152-6f243590df8e",
   "metadata": {},
   "source": [
    "## Output Format\n",
    "### messages\n",
    "Let's create a tool so agent will create some tool messages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27831c76-be27-4ee8-a24d-cc6d455f4968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def wire_transfer_calculator(destination_type: str, transfer_amount: float) -> float:\n",
    "    \"\"\"Calculate standard wire transfer fee based on destination type and amount.\"\"\"\n",
    "    if destination_type.lower() == \"domestic\":\n",
    "        fee = 15.0 if transfer_amount <= 10000 else 25.0\n",
    "    elif destination_type.lower() == \"international\":\n",
    "        fee = 35.0 if transfer_amount <= 10000 else 50.0\n",
    "    else:\n",
    "        fee = 50.0  # Default fee for unknown types\n",
    "    return fee\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879cad42-e41c-4d03-a118-585ff9dcfb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=\"groq:llama-3.1-8b-instant\",\n",
    "    tools=[wire_transfer_calculator],\n",
    "    system_prompt=\"You are a helpful banker. Answer customer queries with warmth and professionalism.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a70fbb-1d26-411c-aa87-6077bdf21868",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke({\"messages\": \"I want to send an international wire transfer of $8,000 to Canada. What will the fee be?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b3f31f-7247-4d9c-811d-48b041d8eb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605faf3d-c76f-499d-abde-6fe0473eea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(result[\"messages\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91779142-2d3a-4e9e-9827-69c538e8f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, msg in enumerate(result[\"messages\"]):\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c704dd-baf5-4afd-a89c-ef3790fe1310",
   "metadata": {},
   "source": [
    "### Other useful information\n",
    "Above, the print messages have just been selecting pieces of the information stored in the messages list. Let's dig into all the information that is available!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1afcfa8-a706-403f-8c29-1f441d174908",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b0568f-41d7-48e3-b69e-f2b8123d941a",
   "metadata": {},
   "source": [
    "You can select just the last message, and you can see where the final message is coming from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bacc660-7997-4da7-9d3e-eee4b8119601",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7254b9e5-f6ac-432e-bf9a-05676f8e4b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"messages\"][-1].usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523f453e-a425-4df0-88b0-a04e6e7612ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"messages\"][-1].response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb5d505-a2db-4f64-9346-03af057b3be6",
   "metadata": {},
   "source": [
    "### Try it on your own!\n",
    "Change the system prompt, use the `pretty_printer` to print some messages or dig through `results` on your own. Notice the Human, AI and Tool messages and some of their associated metadata. Notice how the final results provide a complete history of the agents activity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f921687f-005c-4727-b041-18bafbfaf1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=\"groq:llama-3.1-8b-instant\",\n",
    "    tools=[wire_transfer_calculator],\n",
    "    system_prompt=\"Your SYSTEM prompt here\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e27be2-6bf9-4c0e-b466-8f9e483bfe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, msg in enumerate(result[\"messages\"]):\n",
    "    msg.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
